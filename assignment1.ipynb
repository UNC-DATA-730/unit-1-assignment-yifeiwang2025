{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e757ec2c-1a9a-49c7-928d-ae3e7eb9cefb",
   "metadata": {},
   "source": [
    "## Assignment #1 DATA 730"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12882e8c-a45f-45ee-b13b-368f0099c67e",
   "metadata": {},
   "source": [
    "This assignment tests that you have the course tech stack set up. If you do, you will be able to complete this notebook and turn-in your work by pushing to your assignment repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e522b4-c275-4043-a37f-f2e49eb243bd",
   "metadata": {},
   "source": [
    "## Tech stack checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db31feed-577b-4c7d-a409-6429cad04cfd",
   "metadata": {},
   "source": [
    "*Fill out the checklist below once you have completed each task:*\n",
    "\n",
    "- [ ] GitHub account\n",
    "- [ ] SageMaker Studio Lab account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02701813-a27b-45f9-a48b-9cfe343eac65",
   "metadata": {},
   "source": [
    "**Create the `data730` conda environment by right clicking the `environment.yml` file from the repo in SageMaker Studio Lab and selecting `Build conda Environment`.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158255df-7b9f-4cf4-b644-632172a5152e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc383334-802a-45bf-bc7e-150fdb963bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6235a95-e0a6-4f7a-865a-b1d891796125",
   "metadata": {},
   "source": [
    "## Let's do some statistical inference!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc5e612-a5b6-4a90-90fb-989fcce40874",
   "metadata": {},
   "source": [
    "Read [this article](https://www.theguardian.com/world/2002/jan/04/euro.eu2). \n",
    "\n",
    "Execute the code below to investigate whether the coin is fair..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e16445-2854-49fe-8c5c-0dfd32e0a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions simulate tossing a fair coin n_tosses number of times for n_iterations number of iterations\n",
    "\n",
    "toss_fair_coin_n_times = function(n_tosses = 250) {\n",
    "    result = ifelse(runif(n = n_tosses) < 0.5, 'heads', 'tails')\n",
    "    result\n",
    "}\n",
    "\n",
    "repeat_the_experiment = function(n_iterations, n_tosses = 250) {\n",
    "    n_heads_each_iteration = c()\n",
    "    for (i in 1:n_iterations) {\n",
    "        n_heads = sum(toss_fair_coin_n_times(n_tosses) == 'heads')\n",
    "        n_heads_each_iteration = c(n_heads_each_iteration, n_heads)\n",
    "    } \n",
    "    n_heads_each_iteration\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0333b3d-7cc6-4fa0-813e-f2d4c863be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do 10,000 experiments of 250 tosses and see how often our outcome deviates from what was actually observed (139 heads)\n",
    "\n",
    "n_iterations = 10000\n",
    "n_tosses = 250\n",
    "observed_deviation = 139 - 125 # 139 heads observed, expected value for a fair coin of 125\n",
    "\n",
    "n_heads_each_experiment = repeat_the_experiment(n_iterations, n_tosses)\n",
    "\n",
    "x = mean(abs(n_heads_each_experiment - 125) >= observed_deviation)\n",
    "paste0('With a fair coin we would expect a deviation as large or larger than what we observed ', x*100, '% of times')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf71651-a940-455b-8d30-14660b1aade4",
   "metadata": {},
   "source": [
    "**Do you think the coin was fair?** (Answer below in a markdown cell.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633d8e34-1682-46f4-a341-ae9f5d145174",
   "metadata": {},
   "source": [
    "**The coin was fair.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0fd7bd-b078-4198-8274-2a660ce3c070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-default:Python",
   "language": "python",
   "name": "conda-env-.conda-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
